{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f34bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os, librosa\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "import sklearn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e790269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('audio_data.pkl', 'rb') as f:\n",
    "    audio_data_df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21754354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from class_CNN import DatasetClass\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(audio_data_df, test_size=0.2, random_state=42)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# call my dataclass \n",
    "\n",
    "train_data = DatasetClass(train_df)\n",
    "val_data = DatasetClass(val_df)\n",
    "test_data = DatasetClass(test_df)\n",
    "\n",
    "# save test data to pickle file\n",
    "# with open('test_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_data, f)\n",
    "\n",
    "#call my dataloader \n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64a845f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 127])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6cc6d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UrbanCNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=31744, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model\n",
    "\n",
    "from model_CNN import UrbanCNN\n",
    "import torch\n",
    "\n",
    "model = UrbanCNN()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba2b3503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/week5/wandb/run-20250513_164415-k35d12fd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5/runs/k35d12fd' target=\"_blank\">flick-20250513_1644_15</a></strong> to <a href='https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5' target=\"_blank\">https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5/runs/k35d12fd' target=\"_blank\">https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5/runs/k35d12fd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5/runs/k35d12fd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7dd0f45a24d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb \n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M_%S')\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"week5\",\n",
    "    name=f\"flick-{timestamp}\",\n",
    "    config={\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": 0.001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41f8c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 3.2000, Val Loss: 1.0201\n",
      "Epoch 2, Train Loss: 0.6451, Val Loss: 0.7880\n",
      "Epoch 3, Train Loss: 0.3465, Val Loss: 0.8134\n",
      "Epoch 4, Train Loss: 0.1923, Val Loss: 0.7946\n",
      "Epoch 5, Train Loss: 0.1026, Val Loss: 0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.0721, Val Loss: 0.8398\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▂▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▂▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.07212</td></tr><tr><td>val_loss</td><td>0.83976</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flick-20250513_1644_15</strong> at: <a href='https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5/runs/k35d12fd' target=\"_blank\">https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5/runs/k35d12fd</a><br> View project at: <a href='https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5' target=\"_blank\">https://wandb.ai/lilounina-nina-the-machine-learning-institute/week5</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250513_164415-k35d12fd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for epoch in range(6):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for padded_spec, label in train_loader:\n",
    "        padded_spec = padded_spec.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        output = model(padded_spec)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "  \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for padded_spec, label in val_loader:\n",
    "            padded_spec = padded_spec.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(padded_spec)\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    wandb.log({\"train_loss\": avg_train_loss, \"val_loss\": avg_val_loss})\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "wandb.finish()\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67d9f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_3couches.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
